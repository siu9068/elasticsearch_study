## 1.1 검색 시스템의 이해

### 1.1.1 검색시스템이란?
- 검색엔진
  - 광활한 웹에서 정보를 수집해 검색결과를 제공하는 프로그램
- 검색시스템
  - 대용량 데이터를 기반으로 신뢰성 있는 검색 결과를 제공하기 위해 검색엔진을 기반으로 구축된 시스템을 통칭하는 용어
~~~
검색서비스 > 검색시스템 > 검색엔진
~~~

### 1.1.2 검색 시스템의 구성요소
- 수집기
  - 웹사이트,블로그,카페 등 웹이서 필요한 정보를 수집하는 프로그램
- 스토리지
  - 데이터베이스를 저장하는 물리적 저장소 (검색엔진이 색인한 데이터를 스토리지에 보관)
- 색인기
  - 검색엔진이 수집한 정보를검색가능한 구조로 가공하고 저장하는 역할
- 검색기
  - 색인기와 마찬가지로 형태소 분석기를 이용해 사용자 질의에서 유의미한 용어를 추출해 검색

~~~
수집기 > 색인기 > 스토리지 > 검색기
~~~

### 1.1.3 관계형 데이터베이스와의 차이점
- 데이터베이스
  - 텍스트 매칭을 통한 단순검색 (텍스트를 여러단어로 변형하거나 여러개의 동의어, 유의어 활용검색 불가능)
- 검색엔진
  - 비정형 데이터를 색인하고 검색 가능 (형태소 분석을 토한 사람이 구사하는 자연어, 역색인구조를 바탕으로한 빠른 검색)


##### 엘라스틱서치와 관계형 데이터배이스 비교
|     엘라스틱서치     |    관계형 데이터베이스     |
|:--------------:|:-----------------:|
|  인덱스 (Index)   | 데이터베이스 (Database) |
|   샤드 (Shard)   |  파티션 (Partition)  |
|   타입 (Type)    |    테이블 (Table)    |
| 문서 (Document)  |      행 (Row)      |
|   필드 (Field)   |    열 (Column)     |
|  매핑 (Mapping)  |   스키마 (Schema)    |
|   Query DSL    |        SQL        |

##### CRUD 기능비교
| 엘라스틱서치에서 사용하는 HTTP 메서드 |       기능        | SQL|
|:----------------------:|:---------------:|:---------:|
|          GET           |     데이터 조회      |SELECT|
|          PUT           |     데이터 생성      |INSERT|
|          POST          | 인덱스 업데이트, 데이터조회 | UPDATE,SELECT|
|         DELETE         |      데이터삭제      |  DELETE  |
|          HEAD          |   인덱스의 정보 확인    |  -  |


    curl -X(메서드) http://host:port/(인덱스)/(타입)/(문서 id) -d '{json 데이터}'
curl은 리녹스 기본 명령어로서 이것을 이용하면 터미널 커맨드라인에서 간단하게 http요청을 보낼수 있다.  

## 1.2 검색 시스템과 엘라스틱서치

### 1.2.1 엘라스틱 서치가 강력한 이유
- 오픈소스 검색엔진
  - 오픈소스 검색엔진으로서 전세계에서 수많은 사람들이 사용하고있으며, 버그가 발생하더라도 대부분 빠르게 해결된다.
- 전문검색
  - 대부분의 데이터베이스는 기본쿼리 및 색인구조의 한계로 인해 기본적인 텍스트 검색 기능만 제공하지만,  
  엘라스틱서치는 내용전체를 색인해서 특정 단어가 포함된 문서를 검색하는 등 좀더 고차원적인 전문검색을 지원한다.
- 통계분석
  - 비정형 로그데이터를 수집하고 한곳에 모아 통계분석을 할 수 있다 (키바나와 연결하면 실시간으로 쌓이는 로그를 시각화하고 분석가능)
- 스키마리스(Schemaless)
  - 데이터베이스는 스키마라는 구조에 따라 데이터를 적합한형태로 변경하고 저장하여 관리한다.  
  반면 엘라스틱서치는 정형화되지 않은 다양한 형태의 문서도 자동으로 색인하고 검색할 수 있다.
- Restful API
  - 요청뿐 아니라 응답에도 JSON형식을 사용해서 이기종 플랫폼에서도 이용 가능하다.
- 멀티테넌시(Multi-tenancy)
  - 서로 상이한 인덱스일지라도 검색한 필드명만 같으면 여러개의 인덱스를 한번에 조회할 수 있다. 이를 이용해 멀티테넌시 기능 제공 가능  
- Document-Oriented
  - JSON형식의 구조화된 문서로 인덱스에 저장가능하여 계층구조 문서도 한번의 쿼리로 쉽게 조회 가능하다.
- 역색인(Inverted Index)
  - 일반적인 NoSQL은 역색인을 지원하지않는데 엘라스틱서치는 루씬기반의 검색엔진으로 역색인을 지원한다.  
  역색인이란 종이책의 마지막 페이지에서 제공하는 색인페이지와 비슷하게 제공되는 특수한 데이터구조다
- 확장성과 가용성
  - 엘라스틱서치를 분산 구성해서 확장한다면 대량의 문서를 좀 더 효율적으로 처리할 수 있다.  
  분산 환경에서 데이터는 샤드라는 작은 단위로 나뉘어 제공되며, 인덱스를 만들때마다 샤드의 수를 조절할 수 있다.  
  이를 통해 데이터 종류와 성격에 따라 데이터를 분산해서 빠르게 처리할 수 있다.
  
### 1.2.2 엘라스틱서치의 약점
1. ***실시간이 아니다.***  
일반적으로 색인된 데이터는 통상적으로 1초뒤에나 검색이 가능해진다.  
색인된 데이터가 내부적으로 커밋과 플러시같은 복잡한 과정을 거치기때문에 실시간이 아니며 엄밀히 따지자면 준 실시간이라고 할 수 있다.
2. ***트랜잭션과 롤백 기능을 제공하지 않는다.***  
엘라스틱서치는 기본적으로 분산시스템으로 구성된다. 전체적인 클러스터의 성능향상을 위해 시스템적으로 비용소모가 큰 롤백과 트랜잭션을 지원하지않기때문에  
최악의 경우 데이터손실의 위험이 있다.
3. ***데이터의 업데이트를 제공하지 않는다.***
엘라스틱서치는 업데이트 명령이 요청될 경우 기존 문서를 삭제하고 새로운문서를 생성하는 방식을 사용한다.  
이러한 방식은 단순업데이트에 비해서는 상대적으로 많은 비용이 발생하지만 불변적이라는 이점을 취할수 있어 큰 단점은 아니다.

## 1.3 실습환경 구축

###1.3.1 엘라스틱서치 설치
이 부분은 책의 내용과는 다르게 Docker를 이용하여 구성하였다. (실습환경만 다르게 구축하고 예제데이터는 똑같이 사용할 예정)
1. https://www.docker.com/get-started 에서 OS에 맞는 Docker Desktop을 다운로드하고 설치한다.
2. elastic.Dockerfile을 아래처럼 작성한다.  
   (컨테이너가 실행된 후 해당컨테이너에서 일련의 작업을 수행하기위한 과정. ex > 한글분석기 플러그인 설치 )
~~~dockerfile
# https://www.docker.elastic.co/
FROM docker.elastic.co/elasticsearch/elasticsearch:8.0.0

# Add your elasticsearch plugins setup here
# Example: RUN elasticsearch-plugin install analysis-icu
RUN elasticsearch-plugin install analysis-nori

~~~
3. 도커컨테이너에 덮어씌울 elasticsearch.yml 파일을 정의한다.
~~~yaml
cluster.name: "javacafe-cluster"
node.name: "javacafe-node1"
network.host: 0.0.0.0
http.port: 9200
transport.port: 9300
path.repo: ["/usr/share/elasticsearch/example/search_example","/usr/share/elasticsearch/example/agg_example"]
~~~
4. docker-compose.yml 아래처럼 작성한다.  
   (이후 구축 될 환경인 Kibana, Logstash 와의 연동과 일괄적인 컨테이너 관리를위해 도커컴포즈를 이용한다.)
~~~yaml
version: '3.8'

services:
  elasticsearch:
    build:
      context: ./elasticsearch
      dockerfile: elastic.Dockerfile
    container_name: elasticsearch
#    Dockerfile에서 정의하고 있으므로 주석
#    image: elasticsearch:8.0.0
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - elk
    volumes:
#      bind -> bind mount는 Data가 Host System의 어디에든지 저장될 수 있습니다.
#      Docker Host 또는 Docker Container의 Non-Docker 프로세서들이 언제든지 저장된 Data를 수정할 수 있습니다.
      - /Users/healthport/docker/data:/usr/share/elasticsearch/data
      - type: bind
        source: ./elasticsearch/elasticsearch.yml
        target: /usr/share/elasticsearch/config/elasticsearch.yml
        read_only: true
#      volume -> Docker(Linux에서는 /var/lib/docker/volume/)가 관리하는 Host File System의 일부에 Data가 저장됩니다.
#      Docker에서 Data를 존속시킬 수 있는 Best한 방법
      - type: bind
        source: example
        target: /usr/share/elasticsearch/example
    environment:
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - "discovery.type=single-node"
      - "xpack.security.enabled=false"
#    user: root
#    restart: always
#    privileged: true

#네트워크 생성
networks:
  elk:
    driver: bridge

#볼륨생성
volumes:
  example:
~~~
4. 예제파일을 컨테이너에 세팅하기위해서 example 폴더에 예제파일을 미리 준비한다.
5. 터미널에서 \'docker-compose up -d --build\' 명령어를 입력하면 도커파일 빌드 후 컴포즈에 설정된 설정대로 컨테이너를 실행한다.
6. 해당 컨테이너에 접속하여 세팅정보등이 제대로 적용 되었는지 확인한다.
7. path.repo에서 설정한 물리적인 스냅숏 데이터를 엘라스틱 서치로 인식시키는 작업이 필요하다.
> curl -XPUT 'localhost:9200/_snapshot/javacafe' -d '{
    "type": "fs",
    "settings": {
        "location": "/usr/share/elasticsearch/example/search_example",
        "compress": true
    }
}'
> curl -XPUT 'localhost:9200/_snapshot/apache-web-log' -d '{
    "type": "fs",
    "settings": {
        "location": "/usr/share/elasticsearch/example/agg_example",
        "compress": true
    }
}'
8. 생성된 논리적인 스냅숏을 확인해본다.

> curl -XGET 'localhost:9200/_snapshot/javacafe/_all'
> curl -XGET 'localhost:9200/_snapshot/apache-web-log/_all'

### 1.3.2 키바나 설치
1. 컨테이너끼리의 연동과 일괄 관리를 편하게 하기위해 도커 컴포즈를 이용하여 세팅중이다.  
따라서 키바나용 도커파일을 새로 생성하고, 도커컴포즈에 키바나용 세팅을 추가한다.
2. kibana.Dockerfile을 아래처럼 작성한다.
~~~dockerfile
# https://www.docker.elastic.co/
FROM docker.elastic.co/kibana/kibana:8.0.1
~~~
3. 도커컨테이너에 덮어씌울 kibana.yml 파일을 정의한다.
~~~yaml
server.shutdownTimeout: "5s"
elasticsearch.hosts: [ "http://elasticsearch:9200" ]
monitoring.ui.container.elasticsearch.enabled: true
~~~
4. 기존에 작성된 docker-compose.yml 키바나 세팅정보를 추가한다.
~~~yaml
version: '3.8'

services:
  elasticsearch:
    build:
      context: ./elasticsearch
      dockerfile: elastic.Dockerfile
    container_name: elasticsearch
#    Dockerfile에서 정의하고 있으므로 주석
#    image: elasticsearch:8.0.0
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - elk
    volumes:
#      bind -> bind mount는 Data가 Host System의 어디에든지 저장될 수 있습니다.
#      Docker Host 또는 Docker Container의 Non-Docker 프로세서들이 언제든지 저장된 Data를 수정할 수 있습니다.
      - /Users/healthport/docker/data:/usr/share/elasticsearch/data
      - type: bind
        source: ./elasticsearch/elasticsearch.yml
        target: /usr/share/elasticsearch/config/elasticsearch.yml
        read_only: true
#      volume -> Docker(Linux에서는 /var/lib/docker/volume/)가 관리하는 Host File System의 일부에 Data가 저장됩니다.
#      Docker에서 Data를 존속시킬 수 있는 Best한 방법
      - type: bind
        source: example
        target: /usr/share/elasticsearch/example
    environment:
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - "discovery.type=single-node"
      - "xpack.security.enabled=false"
#    user: root
#    restart: always
#    privileged: true
  
  kibana:
    build:
      context: ./kibana
      dockerfile: kibana.Dockerfile
    container_name: kibana
    ports:
      - "5601:5601"
    networks:
      - elk
    volumes:
      - type: bind
        source: ./kibana/kibana.yml
        target: /usr/share/kibana/config/kibana.yml
        read_only: true
#엘라스틱서치 컨테이너가 구동되었는지 확인하고 실행하기 위한 설정
    depends_on:
      - elasticsearch
    

#네트워크 생성
networks:
  elk:
    driver: bridge

#볼륨생성
volumes:
  example:
~~~
5. 키바나 설치가 완료되면 http://localhost:5601로 접속한다.
6. 메뉴에 DevTools로 이동하면 curl과 유사하지만 더 간편한 요청을 전달 할 수 있는 도구가 나온다.
> GET _search
{
  "query": {
    "match_all": {}
  }
}
> ~~~
> [GET] -> 요청전달 방식이다. GET,POST,PUT,DELETE 를 지정할수있다.  
> GET: 결과반환  
> POST: 변경
> PUT: 삽입
> DELETE: 삭제
> ~~~
> ~~~
> [_search] -> 검색쿼리를 의미한다.  
> _search 앞부분에 인덱스를 명시해서 해당인덱스로만 범위를 한정해서 검색수행이 가능한다.
> 여기서는 어떠한 인덱스도 지정하지 않았기 때문에 전체인덱스를 대상으로 검색이 수행된다.
> ~~~
> ~~~
>  [{"query":{"match_all": {}}}] -> 쿼리본문에 해당되며 curl명령에서는 -d 옵션에 해당한다.  
> json형식으로 작성한다.
> ~~~